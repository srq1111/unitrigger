{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c64c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import random\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from transformers import BertTokenizer, BertForSequenceClassification,BertConfig\n",
    "global extracted_grads\n",
    "global rand_num\n",
    "extracted_grads = []\n",
    "position = 1#concatenation position\n",
    "#the concatenation position of the BERT model is after the [CLS] token\n",
    "\n",
    "\n",
    "#Random Concatenation Mode\n",
    "#position = random.randint(1,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ed5593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1661: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at /mnt/pytorch_model.bin were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /mnt/pytorch_model.bin and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BERT_path = 'pretrained-berts-pytorch/uncased_L-2_H-256_A-4'#path to bert model\n",
    "tokenize = BertTokenizer.from_pretrained(os.path.join(BERT_path,'vocab.txt'))\n",
    "model_config = BertConfig.from_pretrained(os.path.join(BERT_path,'config.json'))\n",
    "Model = BertForSequenceClassification.from_pretrained(os.path.join(BERT_path,'pytorch_model.bin'),config = model_config)\n",
    "#Load model related information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8aa63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters:9591554\n",
      " each layer parameters[7813632, 131072, 512, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 65536, 256, 65536, 256, 65536, 256, 256, 256, 262144, 1024, 262144, 256, 256, 256, 65536, 256, 512, 2] \n"
     ]
    }
   ],
   "source": [
    "#Print the number of Total Parameters\n",
    "total = [param.nelement() for param in Model.parameters()]\n",
    "print(f'total parameters:{format(sum(total))}\\n each layer parameters{total} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdcaa5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir,is_train):#for training the model\n",
    "    data,labels = [],[]\n",
    "    for label in ('neg','pos'):\n",
    "        data_path = os.path.join(data_dir,'train' if is_train else 'test',label)\n",
    "        for file in os.listdir(data_path):\n",
    "            with open (os.path.join(data_path,file),'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n',' ')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data,labels\n",
    "\n",
    "def read_test_data(data_dir,is_train):\n",
    "    data,labels = [],[]\n",
    "    label = 'pos'#choose a label to attack\n",
    "    data_path = os.path.join(data_dir,'train' if is_train else 'test',label)\n",
    "    for file in os.listdir(data_path):\n",
    "        with open (os.path.join(data_path,file),'rb') as f:\n",
    "            review = f.read().decode('utf-8').replace('\\n',' ')\n",
    "            data.append(review)\n",
    "            labels.append(1 if label == 'pos' else 0)\n",
    "    return data,labels\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Constructs a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def try_all_gpus():\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "def load_imdb_data(batch_size, num_steps=500):\n",
    "    data_dir = 'aclImdb'#Path to download dataset\n",
    "    train_data = read_data(data_dir,True)\n",
    "    test_data = read_test_data(data_dir,False)\n",
    "    train_encoding = tokenize(train_data[0], return_tensors=\"pt\",padding = True,truncation = True,max_length = num_steps)\n",
    "    test_encoding = tokenize(test_data[0], return_tensors=\"pt\",padding = True,truncation = True,max_length = num_steps)\n",
    "    train_iter = load_array((train_encoding['input_ids'],train_encoding['token_type_ids'], torch.tensor(train_data[1])),\n",
    "                                batch_size)\n",
    "    test_iter = load_array((test_encoding['input_ids'],test_encoding['token_type_ids'], torch.tensor(test_data[1])),\n",
    "                               batch_size,\n",
    "                               is_train=False)\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cf083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_iter,lr,num_epochs,device):\n",
    "    print('---------------------------start---------------------')\n",
    "    optimizer = torch.optim.AdamW(net.parameters(),lr=lr)\n",
    "    net = net.to(device[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        print(f' epoch {epoch+1}')\n",
    "        train_losses = []\n",
    "        train_accs = []\n",
    "        train_length = 0\n",
    "        for batch in tqdm(train_iter):\n",
    "            a,b, y = batch\n",
    "            a = a.to(device[0])\n",
    "            b = b.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            outputs = net(input_ids = a,token_type_ids = b,labels = y)\n",
    "            logits = outputs.logits\n",
    "            l = outputs.loss\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            acc = (logits.argmax(dim=-1) == y).float().mean()\n",
    "            train_losses.append(l)\n",
    "            train_accs.append(acc)\n",
    "            train_length += len(y)\n",
    "        print(\"Learning rate for epoch %d：%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n",
    "        train_loss = sum(train_losses) / len(train_iter)\n",
    "        train_acc = sum(train_accs) / len(train_iter)\n",
    "        print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}   acc = {train_acc:.5f}\")\n",
    "    print('Training process has finished.')\n",
    "    print('the loss of model {:.3f}'.format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7349a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_trigger_tokens(trigger,num_trigger_tokens):#Initialize trigger tokens, we use 'the' as initial trigger token\n",
    "    trigger_token_ids = [1996] * num_trigger_tokens#1996---'the'\n",
    "    trigger_token_tensor = torch.tensor(trigger_token_ids)\n",
    "    return trigger_token_tensor\n",
    "\n",
    "def evaluate(net,test_iter,trigger_token_tensor):#evaluate the accuracy of the model after concatenating the initial trigger token\n",
    "    net = net.to(device[0])\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    n = torch.tensor([0]*len(trigger_token_tensor))\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    n = n.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            a,b, y = batch\n",
    "            a = torch.cat((a[:,:position],m.repeat_interleave(a.shape[0],dim = 0),a[:,position:]),dim = 1)\n",
    "            b = torch.cat((b[:,:position],n.repeat_interleave(b.shape[0],dim = 0),b[:,position:]),dim = 1)\n",
    "            a = a.to(device[0])\n",
    "            b = b.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            outputs = net(input_ids = a,token_type_ids = b,labels = y)\n",
    "            acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "            valid_accs.append(acc)\n",
    "    valid_acc = sum(valid_accs)/len(test_iter)\n",
    "    return valid_acc\n",
    "\n",
    "def extract_grad_hook(net, grad_in, grad_out):#store the gradient in extracted_grads\n",
    "    extracted_grads.append(grad_out[0].mean(dim = 0))\n",
    "def add_hook(net):\n",
    "    for module in net.modules():\n",
    "            if isinstance(module, nn.Embedding):\n",
    "                hook = module.register_backward_hook(extract_grad_hook)\n",
    "                break\n",
    "    return hook\n",
    "\n",
    "def get_gradient(net,test_iter,trigger_token_tensor):#Calculate the loss to get the gradient\n",
    "    net = net.to(device[0])\n",
    "    net.train()\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    n = torch.tensor([0]*len(trigger_token_tensor))\n",
    "    n = n.unsqueeze(0)\n",
    "    optimizer = torch.optim.AdamW(net.parameters())\n",
    "    for batch in tqdm(test_iter):\n",
    "        a,b, y = batch\n",
    "        a = torch.cat((a[:,:position],m.repeat_interleave(a.shape[0],dim = 0),a[:,position:]),dim = 1)\n",
    "        b = torch.cat((b[:,:position],n.repeat_interleave(b.shape[0],dim = 0),b[:,position:]),dim = 1)\n",
    "        a = a.to(device[0])\n",
    "        b = b.to(device[0])\n",
    "        y = y.to(device[0])\n",
    "        outputs = net(input_ids = a,token_type_ids = b,labels = y)\n",
    "        l = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "    \n",
    "\n",
    "def process_gradient(length,num_trigger_tokens):#Process the gradient to get the average gradient\n",
    "    extracted_grads_copy = extracted_grads\n",
    "    extracted_grads_copy[0] = extracted_grads_copy[0]\n",
    "    temp = extracted_grads_copy[0]\n",
    "    temp = temp.unsqueeze(0)\n",
    "    for i in range(1,length-1):\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i]\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i].unsqueeze(0)\n",
    "        temp = torch.cat((temp,extracted_grads_copy[i]),dim = 0)\n",
    "    average_grad = temp.mean(dim = 0)[position:position+num_trigger_tokens]########\n",
    "    return average_grad\n",
    "\n",
    "def hotflip_attack(averaged_grad, embedding_matrix,\n",
    "                    num_candidates=1,increase_loss=False):#Return candidates according to Equation 3\n",
    "    averaged_grad = averaged_grad.cpu()\n",
    "    embedding_matrix = embedding_matrix.cpu()\n",
    "    averaged_grad = averaged_grad.unsqueeze(0)\n",
    "    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n",
    "                                                 (averaged_grad, embedding_matrix))   #Equation 3\n",
    "    if not increase_loss:\n",
    "        gradient_dot_embedding_matrix *= -1 \n",
    "        # lower versus increase the class probability.\n",
    "    if num_candidates > 1: # get top k options\n",
    "        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n",
    "        return best_k_ids.detach().cpu().numpy()[0]#Return candidates\n",
    "    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n",
    "    return best_at_each_step[0].detach().cpu().numpy()\n",
    "\n",
    "def get_embedding_weight(net):\n",
    "    for module in net.modules():\n",
    "            if isinstance(module, nn.Embedding):\n",
    "                weight =  module.weight\n",
    "                break\n",
    "    return weight\n",
    "\n",
    "#\n",
    "def select_best_candid(net,test_iter,candid_trigger,trigger_token,valid_acc):#Concatenate each candidate to each input to determine the final trigger token\n",
    "    n = torch.tensor([0]*len(trigger_token))\n",
    "    n = n.unsqueeze(0)\n",
    "    trigger_token = trigger_token.unsqueeze(0)\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    for i in range(candid_trigger.shape[0]):\n",
    "        trigger_token_temp = deepcopy(trigger_token)\n",
    "        for j in range(candid_trigger.shape[1]):\n",
    "            trigger_token_temp[0,i] = candid_trigger[i,j]\n",
    "            valid_accs = []\n",
    "            for batch in tqdm(test_iter):\n",
    "                a,b, y = batch\n",
    "                a = torch.cat((a[:,:position],trigger_token_temp.repeat_interleave(a.shape[0],dim = 0),\n",
    "                               a[:,position:]),dim = 1)\n",
    "                b = torch.cat((b[:,:position],n.repeat_interleave(b.shape[0],dim = 0),\n",
    "                               b[:,position:]),dim = 1)\n",
    "                a = a.to(device[0])\n",
    "                b = b.to(device[0])\n",
    "                y = y.to(device[0])\n",
    "                outputs = net(input_ids = a,token_type_ids = b,labels = y)\n",
    "                acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "                valid_accs.append(acc)\n",
    "            temp = sum(valid_accs)/len(test_iter)\n",
    "            if temp < valid_acc:\n",
    "                valid_acc = temp \n",
    "                trigger_token[0,i] = candid_trigger[i,j]\n",
    "    return trigger_token[0],valid_acc#Return the final trigger token and the accuracy after the attack\n",
    "\n",
    "def collection_attack(net,test_iter,num_candidates,num_epoch,trigger = 'the',#Summarize each function\n",
    "                      num_trigger_tokens=3):\n",
    "    trigger_token_tensor = init_trigger_tokens(trigger,num_trigger_tokens)\n",
    "    print(f'Concatenation location:{position}')\n",
    "    valid_acc = evaluate(net,test_iter,trigger_token_tensor)\n",
    "    print(f'Initial trigger tokens state：the accuracy {valid_acc:.5f}')\n",
    "    embedding_weight = get_embedding_weight(net)\n",
    "    for i in range(num_epoch):\n",
    "        extracted_grads.clear()\n",
    "        hook = add_hook(net)\n",
    "        get_gradient(net,test_iter,trigger_token_tensor)\n",
    "        hook.remove()\n",
    "        average_grad = process_gradient(len(test_iter),num_trigger_tokens)\n",
    "        hot_token = hotflip_attack(average_grad,embedding_weight,num_candidates,increase_loss = True)\n",
    "        hot_token_tensor = torch.from_numpy(hot_token)\n",
    "        trigger_token_tensor,valid_acc = select_best_candid(net,test_iter,hot_token_tensor,trigger_token_tensor,valid_acc)\n",
    "        print(f'after {i+1} rounds of attacking\\ntriggers: {trigger_token_tensor} \\nthe accuracy :{valid_acc:.5f} ')\n",
    "    return trigger_token_tensor,valid_acc#Return the final trigger tokens (trigger length) and the accuracy after the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748d0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter,test_iter = load_imdb_data(10)\n",
    "#Data preprocessing and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d0c905-52c3-4a44-b09f-c465cc47901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = try_all_gpus()\n",
    "#Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18519e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(Model,train_iter,5e-6,3,device)\n",
    "#base BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(Model,train_iter,5e-5,3,device)\n",
    "#else BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51bff0ea-eeb4-4e42-b4fb-e6b709da5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy of the model on the test set when no trigger token is concatenated\n",
    "def evaluate_no(net,test_iter):\n",
    "    net = net.to(device[0])\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            a,b, y = batch\n",
    "            a = a.to(device[0])\n",
    "            b = b.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            outputs = net(input_ids = a,token_type_ids = b,labels = y)\n",
    "            acc = (outputs.logits.argmax(dim=-1) == y).float().mean()\n",
    "            valid_accs.append(acc)\n",
    "    valid_acc = sum(valid_accs)/len(test_iter)\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e53c8a-0ded-4c5f-b599-086c142aba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_no(Model,test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab94e7d-e19c-485c-bd10-a3980e7fe2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_attack(Model,test_iter,5,10,trigger = 'the',num_trigger_tokens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7443b885-6933-4c9a-8819-b2dd7d4807d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(net, sequence):\n",
    "    \"\"\"The model's prediction for an input\"\"\"\n",
    "    predict_sequence = tokenize(sequence)\n",
    "    a = torch.tensor(predict_sequence['input_ids'])\n",
    "    b = torch.tensor(predict_sequence['token_type_ids'])\n",
    "    a = a.to(device[0])\n",
    "    b = b.to(device[0])\n",
    "    a = a.unsqueeze(0)\n",
    "    b = b.unsqueeze(0)\n",
    "    outputs = Model(input_ids = a,token_type_ids = b)\n",
    "    label = torch.argmax(outputs.logits, dim=1)\n",
    "    return outputs.logits,'positive' if label == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93238a16-8ea0-4d61-820d-bda40b5ed779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Figure 1\n",
    "predict_sentiment(Model,\"If you had asked me how the movie was throughout the film, I would have told you it was great! However, I left the theatre feeling unsatisfied. After thinking a little about it, I believe the problem was the pace of the ending. I feel that the majority of the movie moved kind of slow, and then the ending developed very fast. So, I would say the ending left me disappointed.<br /><br />I thought that the characters were well developed. Costner and Kutcher both portrayed their roles very well. Yes! Ashton Kutcher can act! Also, the different relationships between the characters seemed very real. Furthermore,I thought that the different plot lines were well developed. Overall, it was a good movie and I would recommend seeing it.<br /><br />In conclusion: Good Characters, Great Plot, Poorly Written/Edited Ending. Still, Go See It!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
