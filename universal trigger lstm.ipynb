{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51425dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "import random\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from d2l import torch as d2l\n",
    "global extracted_grads\n",
    "global insert_num\n",
    "\n",
    "extracted_grads = []\n",
    "position = 0#concatenation position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da65a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir,is_train):#for training the model\n",
    "    data,labels = [],[]\n",
    "    for label in ('neg','pos'):\n",
    "        data_path = os.path.join(data_dir,'train' if is_train else 'test',label)\n",
    "        for file in os.listdir(data_path):\n",
    "            with open (os.path.join(data_path,file),'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n',' ')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data,labels\n",
    "\n",
    "def read_test_data(data_dir,is_train):\n",
    "    data,labels = [],[]\n",
    "    label = 'neg'#Choose a label to attack\n",
    "    data_path = os.path.join(data_dir,'train' if is_train else 'test',label)\n",
    "    for file in os.listdir(data_path):\n",
    "        with open (os.path.join(data_path,file),'rb') as f:\n",
    "            review = f.read().decode('utf-8').replace('\\n',' ')\n",
    "            data.append(review)\n",
    "            labels.append(1 if label == 'pos' else 0)\n",
    "    return data,labels\n",
    "\n",
    "def preprocess(text):\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?)(') and prev_char != ' '\n",
    "    T = []\n",
    "    out = []\n",
    "    for i,t in enumerate(text):\n",
    "        lower = t.replace('<br />',' ').lower()\n",
    "        T.append(lower)   \n",
    "        out.append(''.join([' ' + char if j > 0 and no_space(char, T[i][j-1]) else char\n",
    "               for j, char in enumerate(T[i])]))\n",
    "    return out\n",
    "\n",
    "def tokenize(lines, token='word'): \n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('error: unknown token type：' + token)\n",
    "\n",
    "class vocabulary:\n",
    "    def __init__(self,tokens = None,min_freg = 0,reserved_token = None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_token is None:\n",
    "            reserved_token = []\n",
    "        count = corpus_count(tokens)\n",
    "        self.token_fre = sorted(count.items(),key = lambda x:x[1],reverse = True)\n",
    "        self.unk,unique_token = 0,['<unk>'] + reserved_token\n",
    "        unique_token += [token for token,fre in self.token_fre\n",
    "                         if fre >= min_freg and token not in unique_token]\n",
    "        self.idx_to_token, self.token_to_idx = [], dict()\n",
    "        for token in unique_token:\n",
    "            self.idx_to_token.append(token) \n",
    "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    def to_tokens(self,indexes):\n",
    "        if not isinstance(indexes,(list,tuple)):\n",
    "            return self.idx_to_token[indexes]\n",
    "        return [self.to_tokens(index) for index in indexes]\n",
    "            \n",
    "def corpus_count(tokens):\n",
    "    if len(tokens) == 0 or isinstance(tokens[0],list):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps] \n",
    "    return line + [padding_token] * (num_steps - len(line)) \n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True): \n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def try_all_gpus(): \n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.LSTM:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "def load_imdb_data(batch_size, num_steps=1000):\n",
    "    data_dir = '/mnt/aclImdb'#Path to download dataset\n",
    "    train_data = read_data(data_dir,True)\n",
    "    test_data = read_test_data(data_dir,False)\n",
    "    train_tokens_pre = preprocess(train_data[0])\n",
    "    test_tokens_pre = preprocess(test_data[0])\n",
    "    train_tokens = tokenize(train_tokens_pre)\n",
    "    test_tokens = tokenize(test_tokens_pre)\n",
    "    vocab = vocabulary(train_tokens, min_freg = 5,reserved_token = ['<pad>'])\n",
    "    train_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "    test_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n",
    "    train_iter = load_array((train_features, torch.tensor(train_data[1])),\n",
    "                                batch_size)\n",
    "    test_iter = load_array((test_features, torch.tensor(test_data[1])),\n",
    "                               batch_size,\n",
    "                               is_train=False)\n",
    "    return train_iter, test_iter,train_features,torch.tensor(train_data[1]), vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30cf52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-LSTM Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout,**kwargs):\n",
    "        super(Model,self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.encoder = nn.LSTM(embed_size,num_hiddens,num_layers=num_layers,bidirectional=True)\n",
    "        self.dense = nn.Linear(num_hiddens * 4 ,2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self,inputs):\n",
    "        inputs = self.embedding(inputs.T)\n",
    "        self.encoder.flatten_parameters()\n",
    "        output,_ = self.encoder(inputs)\n",
    "        encoding = torch.cat((output[0],output[-1]),dim = 1)\n",
    "        outs = self.dense(self.dropout(encoding))\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7a27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_embedding(net):#load the pretrained 100-dimensional GloVe\n",
    "    glove_embedding = d2l.TokenEmbedding('glove.6b.100d')\n",
    "    embeds = glove_embedding[vocab.idx_to_token]\n",
    "    net.embedding.weight.data.copy_(embeds)\n",
    "    net.embedding.weight.requires_grad = True\n",
    "\n",
    "def train(net,train_iter,lr,num_epochs,device):\n",
    "    print('---------------------------start---------------------')\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    optimizer = torch.optim.AdamW(net.parameters(),lr=lr)\n",
    "    net = net.to(device[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        print(f' epoch {epoch+1}')\n",
    "        train_losses = []\n",
    "        train_accs = []\n",
    "        train_length = 0\n",
    "        for batch in tqdm(train_iter):\n",
    "            x, y = batch\n",
    "            x = x.to(device[0])\n",
    "            y = y.to(device[0])\n",
    "            logits = net(x)\n",
    "            l = loss(logits,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            acc = (logits.argmax(dim=-1) == y.to(device[0])).float().mean()\n",
    "            train_losses.append(l.sum())\n",
    "            train_accs.append(acc)\n",
    "            train_length += len(y)\n",
    "        print(\"Learning rate for epoch %d：%f\" % (epoch+1,optimizer.param_groups[0]['lr']))\n",
    "        train_loss = sum(train_losses) / train_length\n",
    "        train_acc = sum(train_accs) / len(train_iter)\n",
    "        print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}   acc = {train_acc:.5f}\")\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "    print('saving model with loss {:.3f}'.format(train_loss))\n",
    "    save_path = f'./model_lstm.pth'\n",
    "    torch.save(net.state_dict(),save_path)\n",
    "\n",
    "\n",
    "def init_trigger_tokens(trigger,num_trigger_tokens):#Initialize trigger tokens\n",
    "    trigger_token_ids = [vocab[trigger] ]* num_trigger_tokens\n",
    "    trigger_token_tensor = torch.tensor(trigger_token_ids)\n",
    "    return trigger_token_tensor\n",
    "\n",
    "def evaluate(net,test_iter,trigger_token_tensor):#evaluate the accuracy of the model after concatenating the initial trigger token\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            x, y = batch\n",
    "            x = torch.cat((x[:,:position],m.repeat_interleave(x.shape[0],dim = 0),x[:,position:]),dim = 1)\n",
    "            logits = net(x.to(device[0]))\n",
    "            acc = (logits.argmax(dim=-1) == y.to(device[0])).float().mean()\n",
    "            valid_accs.append(acc)\n",
    "    valid_acc = sum(valid_accs)/len(test_iter)\n",
    "    return valid_acc\n",
    "\n",
    "def extract_grad_hook(net, grad_in, grad_out):#store the gradient in extracted_grads\n",
    "    extracted_grads.append(grad_out[0].mean(dim = 1))\n",
    "def add_hook(net):\n",
    "    for module in net.modules():\n",
    "            if isinstance(module, nn.Embedding):\n",
    "                hook = module.register_backward_hook(extract_grad_hook)\n",
    "    return hook\n",
    "\n",
    "def get_gradient(net,test_iter,trigger_token_tensor):#Calculate the loss to get the gradient\n",
    "    net.train()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    m = deepcopy(trigger_token_tensor)\n",
    "    m = m.unsqueeze(0)\n",
    "    optimizer = torch.optim.AdamW(net.parameters())\n",
    "    for batch in tqdm(test_iter):\n",
    "        x, y = batch\n",
    "        x = torch.cat((x[:,:position],m.repeat_interleave(x.shape[0],dim = 0),x[:,position:]),dim = 1)\n",
    "        x = x.to(device[0])\n",
    "        y = y.to(device[0])\n",
    "        l = loss(net(x),y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "    \n",
    "\n",
    "def process_gradient(length,num_trigger_tokens):#Process the gradient to get the average gradient\n",
    "    extracted_grads_copy = deepcopy(extracted_grads)\n",
    "    extracted_grads_copy[0] = extracted_grads_copy[0].cpu()\n",
    "    temp = extracted_grads_copy[0]\n",
    "    temp = temp.unsqueeze(0)\n",
    "    for i in range(1,length-1):\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i].cpu()\n",
    "        extracted_grads_copy[i] = extracted_grads_copy[i].unsqueeze(0)\n",
    "        temp = torch.cat((temp,extracted_grads_copy[i]),dim = 0)\n",
    "    average_grad = temp.mean(dim = 0)[position:position+num_trigger_tokens]\n",
    "    return average_grad\n",
    "\n",
    "def hotflip_attack(averaged_grad, embedding_matrix,\n",
    "                    num_candidates=1,increase_loss=False):#Return candidates according to Equation 3\n",
    "    averaged_grad = averaged_grad.cpu()\n",
    "    embedding_matrix = embedding_matrix.cpu()\n",
    "    averaged_grad = averaged_grad.unsqueeze(0)\n",
    "    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n",
    "                                                 (averaged_grad, embedding_matrix))#Equation 3\n",
    "    if not increase_loss:\n",
    "        gradient_dot_embedding_matrix *= -1 \n",
    "    if num_candidates > 1: \n",
    "        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n",
    "        return best_k_ids.detach().cpu().numpy()[0]#Return candidates\n",
    "    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n",
    "    return best_at_each_step[0].detach().cpu().numpy()\n",
    "\n",
    "def get_embedding_weight(net):\n",
    "    for module in net.modules():\n",
    "            if isinstance(module, nn.Embedding):\n",
    "                weight =  module.weight\n",
    "    return weight\n",
    "\n",
    "#\n",
    "def select_best_candid(net,test_iter,candid_trigger,trigger_token,valid_acc):#Concatenate each candidate to each input to determine the final trigger token\n",
    "    trigger_token = trigger_token.unsqueeze(0)\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    for i in range(candid_trigger.shape[0]):\n",
    "        trigger_token_temp = deepcopy(trigger_token)\n",
    "        for j in range(candid_trigger.shape[1]):\n",
    "            trigger_token_temp[0,i] = candid_trigger[i,j]\n",
    "            valid_accs = []\n",
    "            for batch in tqdm(test_iter):\n",
    "                x, y = batch\n",
    "                x = torch.cat((x[:,:position],trigger_token_temp.repeat_interleave(x.shape[0],dim = 0),\n",
    "                               x[:,position:]),dim = 1)\n",
    "                logits = net(x.to(device[0]))\n",
    "                acc = (logits.argmax(dim=-1) == y.to(device[0])).float().mean()\n",
    "                valid_accs.append(acc)\n",
    "            temp = sum(valid_accs)/len(test_iter)\n",
    "            if temp < valid_acc:\n",
    "                valid_acc = temp \n",
    "                trigger_token[0,i] = candid_trigger[i,j]\n",
    "    return trigger_token[0],valid_acc#Return the final trigger token and the accuracy after the attack\n",
    "\n",
    "def collection_attack(net,test_iter,num_candidates,num_epoch,trigger = 'the',#Summarize each function\n",
    "                      num_trigger_tokens=3):\n",
    "    trigger_token_tensor = init_trigger_tokens(trigger,num_trigger_tokens)\n",
    "    valid_acc = evaluate(net,test_iter,trigger_token_tensor)\n",
    "    print(f'unattacked state：the accuracy {valid_acc:.5f}')\n",
    "    embedding_weight = get_embedding_weight(net)\n",
    "    for i in range(num_epoch):\n",
    "        torch.cuda.empty_cache()\n",
    "        extracted_grads.clear()\n",
    "        hook = add_hook(net)\n",
    "        get_gradient(net,test_iter,trigger_token_tensor)\n",
    "        hook.remove()\n",
    "        average_grad = process_gradient(len(test_iter),num_trigger_tokens)\n",
    "        hot_token = hotflip_attack(average_grad,embedding_weight,num_candidates,increase_loss = True)\n",
    "        hot_token_tensor = torch.from_numpy(hot_token)\n",
    "        #print(hot_token_tensor)\n",
    "        trigger_token_tensor,valid_acc = select_best_candid(net,test_iter,hot_token_tensor,trigger_token_tensor,valid_acc)\n",
    "        print(f'after {i+1} rounds of attacking\\ntriggers: {trigger_token_tensor} \\ntriggers tokens:{vocab.to_tokens(trigger_token_tensor.numpy().tolist())} \\nthe accuracy :{valid_acc:.5f} ')\n",
    "    return trigger_token_tensor,valid_acc#Return the final trigger tokens (trigger length) and the accuracy after the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd5113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter,train_features,train_labels,vocab = load_imdb_data(batch_size)#Data preprocessing and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3269a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model initialization\n",
    "embed_size, num_hiddens, num_layers, device, dropout = 100, 100, 2, try_all_gpus(), 0.1\n",
    "net = Model(len(vocab), embed_size, num_hiddens, num_layers,dropout)\n",
    "net.apply(init_weights)\n",
    "put_embedding(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094d6939-e890-458b-b48d-43a273ca222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "lr, num_epochs = 0.01, 3\n",
    "train(net,train_iter,lr,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a32b82-bdb5-4dbc-9c68-e2933687d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_layers = 6,8\n",
    "#num_hiddens = 200,300,400,500\n",
    "#The learning rate and number of epochs apply to the above hyperparameter models\n",
    "lr, num_epochs = 0.001, 7\n",
    "train(net,train_iter,lr,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51769f80-fe86-4bbd-a81a-c460e625eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy of the model on the test set when no trigger token is concatenated\n",
    "def evaluate_no(net,test_iter):\n",
    "    net.eval()\n",
    "    valid_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_iter):\n",
    "            x, y = batch\n",
    "            logits = net(x.to(device[0]))\n",
    "            acc = (logits.argmax(dim=-1) == y.to(device[0])).float().mean()\n",
    "            valid_accs.append(acc)\n",
    "    valid_acc = sum(valid_accs)/len(test_iter)\n",
    "    print(f'without any trigger token：the accuracy {valid_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69107ce-5c54-4702-9895-a0aa8cf282e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_no(net,test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e36a44-b4f9-4165-8f4d-4efb2760e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_candidates,num_epoch = 5,10\n",
    "trigger_token_tensor,valid_acc = collection_attack(net,test_iter,num_candidates,num_epoch,trigger='the',num_trigger_tokens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3910ad-f23b-4caa-8d10-58b2b3b3337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(net, vocab, sequence):\n",
    "    \"\"\"The model's prediction for an input\"\"\"\n",
    "    sequence = torch.tensor(vocab[sequence.split()], device=d2l.try_gpu())\n",
    "    data = net(sequence.reshape(1, -1))\n",
    "    label = torch.argmax(net(sequence.reshape(1, -1)), dim=1)\n",
    "    return data,'positive' if label == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47bd768c-ebbf-4479-9215-0b08839e9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Figure 1\n",
    "predict_sentiment(net,vocab,\"My boyfriend and I went to watch The Guardian.At first I didn't want to watch it, but I loved the movie- It was definitely the best movie I have seen in sometime.They portrayed the USCG very well, it really showed me what they do and I think they should really be appreciated more.Not only did it teach but it was a really good movie. The movie shows what the really do and how hard the job is.I think being a USCG would be challenging and very scary. It was a great movie all around. I would suggest this movie for anyone to see.The ending broke my heart but I know why he did it. The storyline was great I give it 2 thumbs up. I cried it was very emotional, I would give it a 20 if I could!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
